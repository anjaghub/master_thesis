{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_11466/2933139044.py:64: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concatenated_df = pd.concat(dfs, ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Concatenating files together\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m concatenated_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:189\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    187\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:466\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m--> 466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    467\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    469\u001b[0m ]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m         t\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[1;32m    481\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:467\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m    466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reindexed_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupcasted_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcasted_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    469\u001b[0m ]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m         t\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[1;32m    481\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:440\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m upcasted_na\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_valid_na_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;66;03m# note: always holds when self.block.dtype.kind == \"V\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         blk_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m blk_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# we want to avoid filling with np.nan if we are\u001b[39;00m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# using None; we already know that we are all\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# nulls\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36mJoinUnit._is_valid_na_for\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/dtypes/missing.py:741\u001b[0m, in \u001b[0;36mis_valid_na_for_dtype\u001b[0;34m(obj, dtype)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_na_for_dtype\u001b[39m(obj, dtype: DtypeObj) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    isna check that excludes incompatible dtypes\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(obj) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/dtypes/missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/master_thesis/env/lib/python3.9/site-packages/pandas/core/dtypes/missing.py:184\u001b[0m, in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna(obj)\n\u001b[1;32m    181\u001b[0m isnull \u001b[38;5;241m=\u001b[39m isna\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isna\u001b[39m(obj, inf_as_na: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Detect missing values, treating None, NaN or NA as null. Infinite\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    values will also be treated as null if inf_as_na is True.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    boolean ndarray or boolean\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_scalar(obj):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "# List all data files which should be preprocessed\n",
    "directory = Path('/Users/anja/Desktop/data_mt')\n",
    "data_files = [file.name for file in directory.glob('*.csv')]\n",
    "\n",
    "# Columns needed from raw file\n",
    "desired_columns = ['ident_block_trial', # identifier to determine trial, because dataset is off\n",
    "                    'participant',\n",
    "                    'cc_owner.started', # time when the owner confirm dialog in cc trials was started (to measure if something was off with keep)\n",
    "                    'cc_owner.stopped',\n",
    "                    'yc_owner.started', # time when the owner confirm dialog in yc trials was started (to measure if something was off with keep)\n",
    "                    'yc_owner.stopped',\n",
    "                    'balance.started',\n",
    "                    'balance.stopped',\n",
    "                    'fixation.started',\n",
    "                    'fixation.stopped',\n",
    "                    'round_info.started',\n",
    "                    'round_info.stopped',\n",
    "                    'yc_choice.started',\n",
    "                    'yc_choice.stopped',\n",
    "                    'cc_choice.started',\n",
    "                    'cc_choice.stopped',\n",
    "                    'cc_choice_confirm.started',\n",
    "                    'cc_choice_confirm.stopped',\n",
    "                    'yc_draw_frame.started',\n",
    "                    'yc_draw_frame.stopped',\n",
    "                    'yc_value.started',\n",
    "                    'yc_value.stopped',\n",
    "                    'yc_owner_confirm.started',\n",
    "                    'yc_owner_confirm.stopped',\n",
    "                    'cc_value.started',\n",
    "                    'cc_value.stopped',\n",
    "                    'cc_owner_confirm.started',\n",
    "                    'cc_owner_confirm.stopped'\n",
    "                    ] \n",
    "\n",
    "# Create empty list to store files\n",
    "dfs = []\n",
    "# Read the csv files and create columns in case some are missing\n",
    "for file_name in data_files:\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    # Get the available columns\n",
    "    df_initial = pd.read_csv(file_path, nrows=0) \n",
    "    available_columns = df_initial.columns.tolist()\n",
    "    # Determine which desired columns are available in csv\n",
    "    existing_columns = [col for col in desired_columns if col in available_columns]\n",
    "    # Read the CSV file, using only the existing columns\n",
    "    df = pd.read_csv(file_path, usecols=existing_columns)\n",
    "    # Add the missing columns with empty values\n",
    "    for col in desired_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Concatenating files together\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Putting owner times in one column\n",
    "concatenated_df['owner_started'] = concatenated_df['cc_owner.started'].combine_first(concatenated_df['yc_owner.started'])\n",
    "concatenated_df['owner_stopped'] = concatenated_df['cc_owner.stopped'].combine_first(concatenated_df['yc_owner.stopped'])\n",
    "# Putting value times in one column\n",
    "concatenated_df['value_started'] = concatenated_df['cc_value.started'].combine_first(concatenated_df['yc_value.started'])\n",
    "concatenated_df['value_stopped'] = concatenated_df['cc_value.stopped'].combine_first(concatenated_df['yc_value.stopped'])\n",
    "# Putting owner confirm times in one column\n",
    "concatenated_df['owner_confirm_started'] = concatenated_df['cc_owner_confirm.started'].combine_first(concatenated_df['yc_owner_confirm.started'])\n",
    "concatenated_df['owner_confirm_stopped'] = concatenated_df['cc_owner_confirm.stopped'].combine_first(concatenated_df['yc_owner_confirm.stopped'])\n",
    "# Putting choice confirm times in one column\n",
    "concatenated_df['choice_confirm_started'] = concatenated_df['cc_choice_confirm.started'].combine_first(concatenated_df['yc_draw_frame.started'])\n",
    "concatenated_df['choice_confirm_stopped'] = concatenated_df['cc_choice_confirm.stopped'].combine_first(concatenated_df['yc_draw_frame.stopped'])\n",
    "\n",
    "# Calculate durations\n",
    "#concatenated_df['round_info_duration'] = concatenated_df['round_info.stopped'] - concatenated_df['round_info.started']\n",
    "concatenated_df['fixation_duration'] = concatenated_df['fixation.stopped'] - concatenated_df['fixation.started']\n",
    "concatenated_df['balance_duration'] = concatenated_df['balance.stopped'] - concatenated_df['balance.started']\n",
    "\n",
    "concatenated_df['cc_choice_duration'] = concatenated_df['cc_choice.stopped'] - concatenated_df['cc_choice.started']\n",
    "concatenated_df['yc_choice_duration'] = concatenated_df['yc_choice.stopped'] - concatenated_df['yc_choice.started']\n",
    "\n",
    "concatenated_df['owner_confirm_duration'] = concatenated_df['owner_confirm_stopped'] - concatenated_df['owner_confirm_started']\n",
    "concatenated_df['value_duration'] = concatenated_df['value_stopped'] - concatenated_df['value_started']\n",
    "concatenated_df['owner_duration'] = concatenated_df['owner_stopped'] - concatenated_df['owner_started']\n",
    "concatenated_df['choice_confirm_duration'] = concatenated_df['choice_confirm_stopped'] - concatenated_df['choice_confirm_started']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
